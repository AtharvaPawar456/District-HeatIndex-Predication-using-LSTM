{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/AtharvaPawar456/District-HeatIndex-Predication-using-LSTM.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/content/District-HeatIndex-Predication-using-LSTM/normalized_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Describe the dataset\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# # Load the dataset\n",
    "# file_path = '/content/District-HeatIndex-Predication-using-LSTM/normalized_data.csv'\n",
    "# data = pd.read_csv(file_path)\n",
    "\n",
    "# Create a vocabulary list for the 'DISTRICT' column\n",
    "district_vocab = list(data['DISTRICT'].unique())\n",
    "district_index = {district: index for index, district in enumerate(district_vocab)}\n",
    "\n",
    "# Map the 'DISTRICT' column to numerical indices\n",
    "data['DISTRICT_INDEX'] = data['DISTRICT'].map(district_index)\n",
    "\n",
    "# Define features and target\n",
    "features = data.drop(['HEAT_INDEX', 'CATEGORY', 'DISTRICT'], axis=1)  # Exclude target, category, and original district columns\n",
    "\n",
    "# target = data['CATEGORY']\n",
    "target = data['HEAT_INDEX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Concatenate features and target for correlation analysis\n",
    "correlation_data = pd.concat([features, target], axis=1)\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = correlation_data.corr()\n",
    "\n",
    "# Plot the heatmap of the correlation matrix\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the correlation of each feature with the target variable\n",
    "target_correlation = correlation_matrix['HEAT_INDEX'].abs().sort_values(ascending=False)\n",
    "\n",
    "# Print the most correlated to least correlated features\n",
    "print(\"Features sorted by correlation with CATEGORY:\")\n",
    "print(target_correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LSTM with All Feature\n",
    "\n",
    "selected_features = ['T2M', 'T_Fahrenheit', 'TS', 'T2M_MIN', 'T2M_MAX', 'T2MWET', 'WS10M_RANGE', 'WD50M', 'WD10M', 'WS10M_MAX', 'RH2M', 'MO', 'WS10M', 'T2MDEW', 'QV2M', 'WS50M', 'LON', 'DISTRICT_INDEX', 'LAT', 'PS', 'PRECTOTCORR', 'YEAR', 'T2M_RANGE', 'DY', 'WS10M_MIN']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Select relevant features based on correlation results\n",
    "selected_features = ['T2M', 'T_Fahrenheit', 'TS', 'T2M_MIN', 'T2M_MAX', 'T2MWET', 'WS10M_RANGE', 'WD50M', 'WD10M', 'WS10M_MAX', 'RH2M', 'MO', 'WS10M', 'T2MDEW', 'QV2M', 'WS50M', 'LON', 'DISTRICT_INDEX', 'LAT', 'PS', 'PRECTOTCORR', 'YEAR', 'T2M_RANGE', 'DY', 'WS10M_MIN']\n",
    "\n",
    "\n",
    "# Use only the selected features and target variable for the model\n",
    "selected_data = correlation_data[selected_features + ['HEAT_INDEX']]\n",
    "\n",
    "# Define features and target\n",
    "features = selected_data[selected_features]\n",
    "target = selected_data['HEAT_INDEX']\n",
    "\n",
    "# Normalize the features\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Reshape features for LSTM input (assuming each row is a time step)\n",
    "features_reshaped = np.reshape(features_scaled, (features_scaled.shape[0], 1, features_scaled.shape[1]))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_reshaped, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1, activation='linear'))  # Output layer for regression with linear activation\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=6, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {round(accuracy * 100, 2)} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model\n",
    "model.save('lstm_model_all_feature.h5')\n",
    "\n",
    "# Save the district_index\n",
    "with open('district_index.pkl', 'wb') as f:\n",
    "    pickle.dump(district_index, f)\n",
    "\n",
    "# Save the input feature name list\n",
    "feature_names = features.columns.tolist()\n",
    "with open('feature_names_all_feature.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_names, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_features = ['T2M', 'RH2M', 'T2MDEW', 'WD10M', 'HEAT_INDEX']\n",
    "__selected_features = ['T2M', 'T_Fahrenheit', 'TS', 'T2M_MIN', 'T2M_MAX', 'T2MWET', 'WS10M_RANGE', 'WD50M', 'WD10M', 'WS10M_MAX', 'RH2M', 'MO', 'WS10M', 'T2MDEW', 'QV2M', 'WS50M', 'LON', 'DISTRICT_INDEX', 'LAT', 'PS', 'PRECTOTCORR', 'YEAR', 'T2M_RANGE', 'DY', 'WS10M_MIN']\n",
    "\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "new_data_for_inference = data.loc[10, __selected_features]\n",
    "\n",
    "print(\"Data for the specified features in the first row:\")\n",
    "print(new_data_for_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "loaded_model = load_model('lstm_model_all_feature.h5')\n",
    "\n",
    "# Load the district_index\n",
    "with open('district_index.pkl', 'rb') as f:\n",
    "    loaded_district_index = pickle.load(f)\n",
    "\n",
    "# Load the input feature name list\n",
    "with open('feature_names_all_feature.pkl', 'rb') as f:\n",
    "    loaded_feature_names = pickle.load(f)\n",
    "\n",
    "\n",
    "# selected_features = ['T2M', 'T_Fahrenheit', 'TS', 'T2M_MIN', 'T2M_MAX', 'T2MWET', 'WS10M_RANGE', 'WD50M', 'WD10M', 'WS10M_MAX', 'RH2M', 'MO', 'WS10M', 'T2MDEW', 'QV2M', 'WS50M', 'LON', 'DISTRICT_INDEX', 'LAT', 'PS', 'PRECTOTCORR', 'YEAR', 'T2M_RANGE', 'DY', 'WS10M_MIN']\n",
    "\n",
    "new_data_for_inference = pd.DataFrame({\n",
    "'T2M'             :  [0.325153],\n",
    "'T_Fahrenheit'       :  [72.91],\n",
    "'TS'              :  [0.336126],\n",
    "'T2M_MIN'         :  [0.431715],\n",
    "'T2M_MAX'         :  [0.305014],\n",
    "'T2MWET'          :  [0.631997],\n",
    "'WS10M_RANGE'     :  [0.164191],\n",
    "'WD50M'           :  [0.609584],\n",
    "'WD10M'           :  [0.614839],\n",
    "'WS10M_MAX'       :  [0.175806],\n",
    "'RH2M'            :  [0.733267],\n",
    "'MO'    :                   [1],\n",
    "'WS10M'           :  [0.176881],\n",
    "'T2MDEW'          :  [0.766538],\n",
    "'QV2M'            :  [0.549058],\n",
    "'WS50M'           :  [0.208062],\n",
    "'LON'               :  [79.293],\n",
    "'DISTRICT_INDEX'    :      [10],\n",
    "'LAT'               :  [19.366],\n",
    "'PS'               :  [0.43377],\n",
    "'PRECTOTCORR'     :  [0.031997],\n",
    "'YEAR'            :      [2001],\n",
    "'T2M_RANGE'       :  [0.367852],\n",
    "'DY'              :         [1],\n",
    "'WS10M_MIN'       :  [0.139295],\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Normalize the features using the previously fitted scaler\n",
    "new_data_scaled = scaler.transform(new_data_for_inference)\n",
    "\n",
    "# Reshape features for LSTM input\n",
    "new_data_reshaped = np.reshape(new_data_scaled, (new_data_scaled.shape[0], 1, new_data_scaled.shape[1]))\n",
    "\n",
    "# Make predictions for HEAT_INDEX\n",
    "heat_index_prediction = model.predict(new_data_reshaped)\n",
    "\n",
    "pred_Heat_index = round(heat_index_prediction.flatten()[0], 2)\n",
    "\n",
    "# Print predicted HEAT_INDEX\n",
    "print(\"Predicted HEAT_INDEX:\", pred_Heat_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the true HEAT_INDEX value for comparison\n",
    "true_heat_index =  74.71      # Provide the true value here\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = round(np.mean(np.abs(pred_Heat_index - true_heat_index)), 6)\n",
    "\n",
    "# Print predicted HEAT_INDEX and MAE\n",
    "print('''\n",
    "# 3. LSTM with All Feature\n",
    "\n",
    "selected_features = ['T2M', 'T_Fahrenheit', 'TS', 'T2M_MIN', 'T2M_MAX', 'T2MWET', 'WS10M_RANGE', 'WD50M', 'WD10M', 'WS10M_MAX', 'RH2M', 'MO', 'WS10M', 'T2MDEW', 'QV2M', 'WS50M', 'LON', 'DISTRICT_INDEX', 'LAT', 'PS', 'PRECTOTCORR', 'YEAR', 'T2M_RANGE', 'DY', 'WS10M_MIN']\n",
    "\n",
    "''')\n",
    "print(\"Predicted HEAT_INDEX:\\t\", pred_Heat_index)\n",
    "print(\"Actual HEAT_INDEX: \\t\", true_heat_index)\n",
    "print(\"\\nMean Absolute Error:\", mae , \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output:\n",
    "\n",
    "Predicted HEAT_INDEX:\t 73.8\n",
    "\n",
    "Actual HEAT_INDEX: \t 74.71\n",
    "\n",
    "Mean Absolute Error: 0.909997 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
