{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/AtharvaPawar456/District-HeatIndex-Predication-using-LSTM.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/content/District-HeatIndex-Predication-using-LSTM/normalized_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Describe the dataset\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# # Load the dataset\n",
    "# file_path = '/content/District-HeatIndex-Predication-using-LSTM/normalized_data.csv'\n",
    "# data = pd.read_csv(file_path)\n",
    "\n",
    "# Create a vocabulary list for the 'DISTRICT' column\n",
    "district_vocab = list(data['DISTRICT'].unique())\n",
    "district_index = {district: index for index, district in enumerate(district_vocab)}\n",
    "\n",
    "# Map the 'DISTRICT' column to numerical indices\n",
    "data['DISTRICT_INDEX'] = data['DISTRICT'].map(district_index)\n",
    "\n",
    "# Define features and target\n",
    "features = data.drop(['HEAT_INDEX', 'CATEGORY', 'DISTRICT'], axis=1)  # Exclude target, category, and original district columns\n",
    "\n",
    "# target = data['CATEGORY']\n",
    "target = data['HEAT_INDEX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Concatenate features and target for correlation analysis\n",
    "correlation_data = pd.concat([features, target], axis=1)\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = correlation_data.corr()\n",
    "\n",
    "# Plot the heatmap of the correlation matrix\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the correlation of each feature with the target variable\n",
    "target_correlation = correlation_matrix['HEAT_INDEX'].abs().sort_values(ascending=False)\n",
    "\n",
    "# Print the most correlated to least correlated features\n",
    "print(\"Features sorted by correlation with CATEGORY:\")\n",
    "print(target_correlation)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
